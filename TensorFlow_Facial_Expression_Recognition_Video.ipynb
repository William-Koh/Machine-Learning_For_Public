{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-12-27 14:39:12 \t    Loss: 0.716\n",
      "End  : 2019-12-27 14:39:45 \tAccuracy: 91.52 %\n",
      "Runtime: 0 Hrs 0 Min 32 Sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import imutils\n",
    "import sys\n",
    "import pytesseract\n",
    "import image\n",
    "import numpy as np\n",
    "import docx\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import keras\n",
    "import PIL\n",
    "import time\n",
    "import pyautogui\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "from fuzzywuzzy import fuzz\n",
    "from autocorrect import spell\n",
    "from nltk.corpus import words\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from keras.preprocessing.image import load_img ,img_to_array ,array_to_img\n",
    "from skimage import data, io, filters, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "from numpy import zeros, newaxis\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "def Read_TrainDATA_Facial_Expression():    \n",
    "\n",
    "########### #######         ##       # ###      ##      #######         ##   ###########   ##                                      \n",
    "     #      ##     ##      ####      # ## #     ##      ##     ##      ####       #       ####                        \n",
    "     #      ##     ##     ##  ##     # ##  #    ##      ##      ##    ##  ##      #      ##  ##                              \n",
    "     #      #######      ##    ##    # ##   #   ##      ##      ##   ##    ##     #     ##    ##                            \n",
    "     #      ##   ##     ##########   # ##    #  ##      ##      ##  ##########    #    ##########                                \n",
    "     #      ##    ##   ##        ##  # ##     # ##      ##     ##  ##        ##   #   ##        ##                              \n",
    "     #      ##     ## ##          ## # ##      ###      #######   ##          ##  #  ##          ##                       \n",
    "                                                           \n",
    "    # Assign Arrays\n",
    "    ImageArray = []\n",
    "    EmotionList = []\n",
    "    ImageArray_for_display = []\n",
    "    \n",
    "    # Read Data from Train Data Excel file\n",
    "    ReadExcel = pd.read_excel(Train_Facial_Expression)\n",
    "    ImageList = ReadExcel['pixels'].tolist()\n",
    "    Emotion_No = ReadExcel['emotion'].tolist()\n",
    "    \n",
    "    # Convert Numbers to Emotions\n",
    "    # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "    for Counter, Value in enumerate(Emotion_No):\n",
    "        if Value   == 0:\n",
    "            EmotionList.append('Angry')\n",
    "        elif Value == 1:\n",
    "            EmotionList.append('Disgust')\n",
    "        elif Value == 2:\n",
    "            EmotionList.append('Fear')\n",
    "        elif Value == 3:\n",
    "            EmotionList.append('Happy')            \n",
    "        elif Value == 4:\n",
    "            EmotionList.append('Sad')            \n",
    "        elif Value == 5:\n",
    "            EmotionList.append('Surprise')            \n",
    "        elif Value == 6:\n",
    "            EmotionList.append('Neutral')     \n",
    "            \n",
    "    for I in ImageList:\n",
    "        Each_Image = [  int(pixel) for pixel in I.split(' ')  ]         \n",
    "        ImageArray.append(np.asarray(Each_Image).reshape(48,48,1)) \n",
    "        ImageArray_for_display.append(np.asarray(Each_Image).reshape(48,48))\n",
    "    \n",
    "    \n",
    "##    # Excel Summary\n",
    "##    ReadExcel.info()\n",
    "       \n",
    "##    # Display Train Data Facial Expression on Screen\n",
    "##    for J in range(30):\n",
    "##        plt.figure(figsize=(1.5,1.5))\n",
    "##        plt.title(EmotionList[J], fontsize=15)\n",
    "##        plt.imshow(ImageArray_for_display[J])\n",
    "        \n",
    "        \n",
    "    return ImageArray, Emotion_No, EmotionList \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def Machine_Learning_Model(ImageArray):  \n",
    "\n",
    "###       ###  #######  #######    ######## #                                                                             \n",
    "####     #### ##     ## ##     ##  #        #                                                         \n",
    "##  #   #  ## ##     ## ##      ## #        #                                           \n",
    "##   # #   ## ##     ## ##      ## ######   #                                                        \n",
    "##    #    ## ##     ## ##      ## #        #                                                         \n",
    "##         ## ##     ## ##     ##  #        #                                                              \n",
    "##         ##  #######  #######    ######## ########                                                                                                    \n",
    "\n",
    "                                \n",
    "    ImageArray = np.array(ImageArray)   \n",
    "##    ImageArray = ImageArray / 255.0   \n",
    "    x_train, x_test, y_train, y_test = train_test_split(ImageArray, Emotion_No, test_size=Test_Data_Size, shuffle=True)\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "#    print(x_train.shape) \n",
    "#   Print the Shape/Dimension of train data as (28709, 48, 48, 1) = (samples, rows, columns, channels)\n",
    "#   Note: x_train is IMAGE & y_train is LABEL\n",
    "#   Note: x_test  is IMAGE & y_test  is LABEL\n",
    "\n",
    "################################################# CNN #################################################\n",
    "# When Filter is 32, there will have 32 different Feature Maps\n",
    "# The more Feature Maps there are, the picture becomes more abstract\n",
    "# Max pooling is used to find the outliers, this is when network sees the feature\n",
    "\n",
    "    # Convolutional Neural Network (CNN)\n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(4, kernel_size=kernelSize, \n",
    "              activation=Model_Activation,      \n",
    "              input_shape=(48,48,1))) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(4, kernel_size=kernelSize, \n",
    "              activation=Model_Activation\n",
    "              ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##    model.add(Conv2D(8, kernel_size=kernelSize, \n",
    "##              activation=Model_Activation,\n",
    "##              padding='same',\n",
    "##              use_bias=False\n",
    "##              ))\n",
    "##    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))    \n",
    "##    model.add(Dropout(0.2))    \n",
    "    \n",
    "#   model.add(Conv2D(4, kernel_size=(3, 3), activation=Model_Activation))    \n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "       \n",
    "################################################# CNN #################################################    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=Model_Activation))\n",
    "    model.add(Dense(1024, activation=Model_Activation))    \n",
    "    model.add(Dense(7, activation=tf.nn.softmax))\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(optimizer=Optimizer_Option, loss=Loss_Option, metrics=['accuracy'])   \n",
    "    \n",
    "    if Weight_Mode == 0:\n",
    "        model.fit(x_train, y_train, epochs=No_of_Epochs)\n",
    "        model.save_weights(os.path.join(Current_Dir,'Model_Weights\\DigitWeights_Trial.h5'))\n",
    "    elif Weight_Mode == 1:\n",
    "        model.load_weights(os.path.join(Current_Dir,Saved_Weight))\n",
    "    \n",
    "    # Model Score\n",
    "    score = model.evaluate(x_test, y_test, verbose=100)\n",
    "    \n",
    "#    # Model Summary\n",
    "#    model.summary()\n",
    "    \n",
    "    return score, model        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Facial_Expression_Prediction(image_file):      \n",
    "\n",
    "#######  #######    ######## #######    #   ####### ###########                                                 \n",
    "##     # ##     ##  #        ##     ##  #  ##            #                                 \n",
    "##     # ##     ##  #        ##      ## # ##             #                      \n",
    "#######  #######    ######   ##      ## # ##             #                         \n",
    "##       ##    ##   #        ##      ## # ##             #                                  \n",
    "##       ##     ##  #        ##     ##  #  ##            #                              \n",
    "##       ##      ## ######## #######    #   #######      #                                       \n",
    "        \n",
    "    \n",
    "        # Convert image to Numbers\n",
    "        image_file = np.array(image_file)\n",
    "        image_file = image_file / 255.0 \n",
    " \n",
    "        # shrink image to 48x48 size. This size must fit Train Data size \n",
    "        image_file = skimage.transform.resize(image_file, [48,48], mode='reflect')\n",
    "        image_file = np.reshape(image_file,(1,48,48,1))         # 4 dimensional image for Tensorflow to process\n",
    "##        print(image_file.shape)\n",
    "        \n",
    "        # Do Prediction\n",
    "        Prediction = model.predict(image_file)\n",
    "        \n",
    "        # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "        if Prediction.argmax()   == 0:\n",
    "            Emotion = 'Angry'\n",
    "        elif Prediction.argmax() == 1:\n",
    "            Emotion = 'Disgust'\n",
    "        elif Prediction.argmax() == 2:\n",
    "            Emotion = 'Fear'\n",
    "        elif Prediction.argmax() == 3:\n",
    "            Emotion = 'Happy'            \n",
    "        elif Prediction.argmax() == 4:\n",
    "            Emotion = 'Sad'            \n",
    "        elif Prediction.argmax() == 5:\n",
    "            Emotion = 'Surprise'            \n",
    "        elif Prediction.argmax() == 6:\n",
    "            Emotion = 'Neutral'        \n",
    "            \n",
    "        return Emotion, Prediction\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                  \n",
    "            \n",
    "            \n",
    "def Facial_Expression_Recognition(Test_Facial, Frontal_Face_Detection_XML, Profile_Face_Detection_XML, Eyes_Detection_XML):\n",
    "\n",
    "#######    ########  ######   #######   ######   ##      # ####### ####### #######  #######  ##      #                     \n",
    "##     ##  #        ##     # ##     ## ##        ###     #    #       #       #    ##     ## ###     #\n",
    "##     ##  #        ##       ##     ## ##        #  #    #    #       #       #    ##     ## #  #    #     \n",
    "#######    ######   ##       ##     ## ##   #### #   #   #    #       #       #    ##     ## #   #   #     \n",
    "##    ##   #        ##       ##     ## ##     ## #    #  #    #       #       #    ##     ## #    #  #           \n",
    "##     ##  #        ##     # ##     ## ##     ## #     ###    #       #       #    ##     ## #     ###            \n",
    "##      ## ########  ######   #######   #######  #      ## #######    #    #######  #######  #      ##                      \n",
    "\n",
    "\n",
    "    # Angle of face detection\n",
    "    Frontal_face_cascade = cv2.CascadeClassifier(Frontal_Face_Detection_XML)\n",
    "    Profile_face_cascade = cv2.CascadeClassifier(Profile_Face_Detection_XML)\n",
    "    eye_cascade  = cv2.CascadeClassifier(Eyes_Detection_XML)\n",
    "\n",
    "    # Activate PC Video\n",
    "    VideoFrame = cv2.VideoCapture(0)\n",
    "    VideoFrame.set(4,640) # set Width\n",
    "    VideoFrame.set(5,480) # set Height    \n",
    "    while(True):\n",
    "\n",
    "        # Capture frame-by-frame, where the frame is \"image_file_for_display\"\n",
    "        ret, image_file_for_display = VideoFrame.read()\n",
    "        image_file_for_display = cv2.flip(image_file_for_display, 1)\n",
    "        image_file = cv2.cvtColor(image_file_for_display, cv2.COLOR_BGR2GRAY)\n",
    "        faces = Frontal_face_cascade.detectMultiScale(image_file_for_display, scaleFactor=1.35, minNeighbors=3, \\\n",
    "                minSize=(15, 15))\n",
    "        \n",
    "        for (x,y,w,h) in faces:  \n",
    "            Extra_Frame = 2\n",
    "            Emotion, Prediction = Facial_Expression_Prediction(image_file[y+Extra_Frame:y+h+Extra_Frame,x-Extra_Frame:x+w+Extra_Frame])\n",
    "            \n",
    "            # Change Colour when Face Expression Changes\n",
    "            FrameColour = (0,0,255)\n",
    "            if str(Emotion) == 'Angry':\n",
    "                FrameColour = (0,0,255) # RED\n",
    "            elif str(Emotion) == 'Disgust':\n",
    "                FrameColour = (0,0,255) # RED\n",
    "            elif str(Emotion) == 'Fear':\n",
    "                FrameColour = (240,0,255) # PINK\n",
    "            elif str(Emotion) == 'Happy':\n",
    "                FrameColour = (0,255,0) # GREEN\n",
    "            elif str(Emotion) == 'Sad':\n",
    "                FrameColour = (0,120,255) # ORANGE\n",
    "            elif str(Emotion) == 'Surprise':\n",
    "                FrameColour = (0,204,204) # YELLOW\n",
    "            elif str(Emotion) == 'Neutral':\n",
    "                FrameColour = (255,0,0) # BLUE\n",
    "            \n",
    "            cv2.putText(image_file_for_display, str(Emotion) + \" \" + str(round(Prediction[0][Prediction.argmax()]*100,1)) + \"%\", \\\n",
    "                        org=(x,y-10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.0,                       \\\n",
    "                        color=FrameColour, thickness=1                    \n",
    "                       )            \n",
    "            cv2.rectangle(image_file_for_display,(x-Extra_Frame,y+Extra_Frame),(x+w+Extra_Frame,y+h+Extra_Frame),FrameColour,2) \n",
    "            \n",
    "            # Display No of Object Captured\n",
    "            cv2.putText(image_file_for_display, \n",
    "                        'Object Captured: '+ str(faces.shape[0]),\n",
    "                        org=(10,20), \n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "                        fontScale=0.6,         \n",
    "                        color=(255,255,255), \n",
    "                        thickness=2                    \n",
    "                       )              \n",
    "            \n",
    "            \n",
    "        cv2.imshow('Facial Expression Recognizer - Colour', image_file_for_display)\n",
    "        #cv2.imshow('Facial Expression Recognizer - Non-Colour', image_file)\n",
    "    \n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    VideoFrame.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def Duration_Calculation():        \n",
    "\n",
    "########### ###### ###       ### #######              \n",
    "    ##        ##   ####     #### #                 \n",
    "    ##        ##   ##  #   #  ## #                  \n",
    "    ##        ##   ##   # #   ## #####                 \n",
    "    ##        ##   ##    #    ## #                   \n",
    "    ##        ##   ##         ## #    \n",
    "    ##      ###### ##         ## ########            \n",
    "                     \n",
    "    EndTime = time.time()\n",
    "    EndDateTime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "    # Calculate script Runtime\n",
    "    Duration = EndTime - StartTime\n",
    "    hours = Duration//3600\n",
    "    Duration = Duration - 3600*hours\n",
    "    minutes = Duration//60\n",
    "    seconds = Duration - 60*minutes\n",
    "    \n",
    "    print(\"Start:\", StartDateTime,                                      '\\t    Loss:', round(score[0], 3)   )\n",
    "    print(\"End  :\", EndDateTime,                                        '\\tAccuracy:', round(score[1]*100, 2),'%'   )\n",
    "    print('Runtime: %d Hrs %d Min %d Sec' %(hours,minutes,seconds)) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "\n",
    "        \n",
    "###     ###      ###      ## ###    ##           \n",
    "####   ####     ## ##     ## ####   ##                 \n",
    "## ## ## ##    ##   ##    ## ## ##  ##              \n",
    "##  ###  ##   #########   ## ##  ## ##                  \n",
    "##       ##  ##       ##  ## ##   ####                         \n",
    "##       ## ##         ## ## ##    ###   \n",
    "\n",
    "                        ########## (CAN EDIT) Switch Mode ##########\n",
    "# Weight_Mode = 0 << Train Model with epochs & Save Weight\n",
    "# Weight_Mode = 1 << Load Saved Weight to Model. Remember to update Saved_Weight\n",
    "Weight_Mode = 1\n",
    "Saved_Weight = 'Model_Weights\\DigitWeights_Good_1.h5'\n",
    "\n",
    "\n",
    "                        ########## (CAN EDIT) Set Parameters for Model ##########\n",
    "Test_Data_Size = 0.15                               #Size of Test data, 0.2 means 20% of total Train data are Test data\n",
    "No_of_Epochs = 35\n",
    "kernelSize=(6,6)                                   #Size of each kernel mapping window\n",
    "Model_Activation = tf.nn.swish                      #'tf.nn.swish','tf.nn.relu'\n",
    "Optimizer_Option = 'Adadelta'                          #'Adam','Adamax','Adagrad','Adadelta','Nadam','SGD','RMSprop'\n",
    "Loss_Option = 'sparse_categorical_crossentropy'    #'sparse_categorical_crossentropy'\n",
    "    \n",
    "\n",
    "                        ########## (DO NOT EDIT) Script process Start Time ##########\n",
    "StartTime = time.time()\n",
    "StartDateTime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "Current_Dir = os.getcwd()    # Get this script current directory\n",
    "\n",
    "\n",
    "                        ########## (DO NOT EDIT) LOCATION OF INPUTS, FOLDERS & IMAGES ##########\n",
    "# Train Data Location    \n",
    "Train_Facial_Expression = os.path.join(Current_Dir,'Train_DATA\\Train_DATA_Facial_Expressions.xlsx')  \n",
    "# Test Data Location\n",
    "Test_Facial = [os.path.join(Current_Dir,'DATA',X) for X in os.listdir(os.path.join(Current_Dir,'DATA'))]   \n",
    "# Frontal Face Detection\n",
    "Frontal_Face_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_frontalface_default.xml')\n",
    "# Profile Face Detection\n",
    "Profile_Face_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_profileface.xml')\n",
    "# Eyes Detection\n",
    "Eyes_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_eye.xml')\n",
    "    \n",
    "\n",
    "                        ########## (DO NOT EDIT) FUNCTIONS ##########\n",
    "ImageArray, Emotion_No, EmotionList = Read_TrainDATA_Facial_Expression()\n",
    "score, model = Machine_Learning_Model(ImageArray)\n",
    "Facial_Expression_Recognition(Test_Facial, Frontal_Face_Detection_XML, Profile_Face_Detection_XML, Eyes_Detection_XML)\n",
    "Duration_Calculation()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
