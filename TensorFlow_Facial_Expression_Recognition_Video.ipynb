{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "28709/28709 [==============================] - 475s 17ms/step - loss: 1.6183 - acc: 0.3613\n",
      "Start: 2019-11-07 15:17:20 \t    Loss: 1.464\n",
      "End  : 2019-11-07 15:51:16 \tAccuracy: 0.435\n",
      "Runtime: 0 Hrs 33 Min 56 Sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import imutils\n",
    "import sys\n",
    "import pytesseract\n",
    "import image\n",
    "import numpy as np\n",
    "import docx\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import keras\n",
    "import PIL\n",
    "import time\n",
    "import pyautogui\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "from fuzzywuzzy import fuzz\n",
    "from autocorrect import spell\n",
    "from nltk.corpus import words\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from keras.preprocessing.image import load_img ,img_to_array ,array_to_img\n",
    "from skimage import data, io, filters, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "from numpy import zeros, newaxis\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "def Read_TrainDATA_Facial_Expression():    \n",
    "\n",
    "########### #######         ##       # ###      ##      #######         ##   ###########   ##                                      \n",
    "     #      ##     ##      ####      # ## #     ##      ##     ##      ####       #       ####                        \n",
    "     #      ##     ##     ##  ##     # ##  #    ##      ##      ##    ##  ##      #      ##  ##                              \n",
    "     #      #######      ##    ##    # ##   #   ##      ##      ##   ##    ##     #     ##    ##                            \n",
    "     #      ##   ##     ##########   # ##    #  ##      ##      ##  ##########    #    ##########                                \n",
    "     #      ##    ##   ##        ##  # ##     # ##      ##     ##  ##        ##   #   ##        ##                              \n",
    "     #      ##     ## ##          ## # ##      ###      #######   ##          ##  #  ##          ##                       \n",
    "                                                           \n",
    "    # Assign Arrays\n",
    "    ImageArray = []\n",
    "    EmotionList = []\n",
    "    \n",
    "    # Read Data from Train Data csv file\n",
    "    ReadCSV = pd.read_csv(Train_Facial_Expression)\n",
    "    ImageList = ReadCSV['pixels'].tolist()\n",
    "    Emotion_No = ReadCSV['emotion'].tolist()\n",
    "    \n",
    "    # Convert Numbers to Emotions\n",
    "    # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "    for Counter, Value in enumerate(Emotion_No):\n",
    "        if Value   == 0:\n",
    "            EmotionList.append('Angry')\n",
    "        elif Value == 1:\n",
    "            EmotionList.append('Disgust')\n",
    "        elif Value == 2:\n",
    "            EmotionList.append('Fear')\n",
    "        elif Value == 3:\n",
    "            EmotionList.append('Happy')            \n",
    "        elif Value == 4:\n",
    "            EmotionList.append('Sad')            \n",
    "        elif Value == 5:\n",
    "            EmotionList.append('Surprise')            \n",
    "        elif Value == 6:\n",
    "            EmotionList.append('Neutral')     \n",
    "            \n",
    "    for I in ImageList:\n",
    "        Each_Image = [  int(pixel) for pixel in I.split(' ')  ]         \n",
    "        ImageArray.append(np.asarray(Each_Image).reshape(48,48,1)) \n",
    "    \n",
    "    \n",
    "##    # CSV Summary\n",
    "##    ReadCSV.info()\n",
    "       \n",
    "##    # Display Train Data Facial Expression on Screen\n",
    "##    for J in range(10):\n",
    "##        plt.figure(figsize=(1.5,1.5))\n",
    "##        plt.title(EmotionList[J], fontsize=15)\n",
    "##        plt.imshow(ImageArray[J])\n",
    "        \n",
    "        \n",
    "    return ImageArray, Emotion_No, EmotionList \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def Machine_Learning_Model(ImageArray):  \n",
    "\n",
    "###       ###  #######  #######    ######## #                                                                             \n",
    "####     #### ##     ## ##     ##  #        #                                                         \n",
    "##  #   #  ## ##     ## ##      ## #        #                                           \n",
    "##   # #   ## ##     ## ##      ## ######   #                                                        \n",
    "##    #    ## ##     ## ##      ## #        #                                                         \n",
    "##         ## ##     ## ##     ##  #        #                                                              \n",
    "##         ##  #######  #######    ######## ########                                                                                                    \n",
    "\n",
    "                                \n",
    "    ImageArray = np.array(ImageArray)   \n",
    "##    ImageArray = ImageArray / 255.0   \n",
    "    x_train, x_test, y_train, y_test = train_test_split(ImageArray, Emotion_No, test_size=0.2, shuffle=True)\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "##    print(x_train.shape) # Print the Shape/Dimension of train data as (28709, 48, 48, 1)=(samples, rows, columns, channels)\n",
    "                         # Note: x_train is IMAGE & y_train is LABEL\n",
    "                         # Note: x_test  is IMAGE & y_test  is LABEL\n",
    "   \n",
    "    \n",
    "##    # Display Train Data on Screen\n",
    "##    for J in range(10):\n",
    "##        plt.figure(figsize=(1.5,1.5))\n",
    "##        plt.title(y_train[J], fontsize=15)\n",
    "##        plt.imshow(x_train[J])     \n",
    "    \n",
    "\n",
    "##    # Neural Network Model \n",
    "##    model = tf.keras.models.Sequential([\n",
    "##      tf.keras.layers.Flatten(input_shape=(48,48)),      # Input Layer\n",
    "##      tf.keras.layers.Dense(128, activation=tf.nn.relu),  # Hidden Layer\n",
    "##      tf.keras.layers.Dense(7, activation=tf.nn.softmax)  # Output Layer\n",
    "##    ])\n",
    "\n",
    "\n",
    "################################################# CNN #################################################\n",
    "# When Filter is 32, there will have 32 different Feature Maps\n",
    "# The more Feature Maps there are, the picture becomes more abstract\n",
    "# Max pooling is used to find the outliers, this is when network sees the feature\n",
    "\n",
    "    # Convolutional Neural Network (CNN)\n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), activation=tf.nn.relu, input_shape=(48,48,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(5, 5), activation=tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "#    model.add(Dropout(0.1))   \n",
    "    \n",
    "################################################# CNN #################################################    \n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "##    model.add(Dense(256, activation=tf.nn.swish))\n",
    "    model.add(Dense(256, activation=tf.nn.relu))\n",
    "    model.add(Dense(7, activation=tf.nn.softmax))\n",
    "\n",
    "    # Compile Model\n",
    "##    model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   \n",
    "    model.fit(x_train, y_train, epochs=1)  \n",
    "       \n",
    "    # Model Score\n",
    "    score = model.evaluate(x_test, y_test, verbose=100)\n",
    "    \n",
    "    # Save / Load Model Weights\n",
    "    model.save_weights(os.path.join(Current_Dir,'Model_Weights\\DigitWeights_Trial.h5'))\n",
    "##    model.load_weights(os.path.join(Current_Dir,'Model_Weights\\DigitWeights_42.4.h5'))\n",
    "    \n",
    "##    # Model Summary\n",
    "##    model.summary()\n",
    "    \n",
    "    return score, model        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Facial_Expression_Prediction(image_file):      \n",
    "\n",
    "#######  #######    ######## #######    #   ####### ###########                                                 \n",
    "##     # ##     ##  #        ##     ##  #  ##            #                                 \n",
    "##     # ##     ##  #        ##      ## # ##             #                      \n",
    "#######  #######    ######   ##      ## # ##             #                         \n",
    "##       ##    ##   #        ##      ## # ##             #                                  \n",
    "##       ##     ##  #        ##     ##  #  ##            #                              \n",
    "##       ##      ## ######## #######    #   #######      #                                       \n",
    "        \n",
    "    \n",
    "        # Convert image to Numbers\n",
    "        image_file = np.array(image_file)\n",
    " \n",
    "        # shrink image to 48x48 size. This size must fit Train Data size \n",
    "        image_file = skimage.transform.resize(image_file, [48,48], mode='reflect')\n",
    "        image_file = np.reshape(image_file,(1,48,48,1))         # 4 dimensional image for Tensorflow to process\n",
    "        \n",
    "        # Do Prediction\n",
    "        Prediction = model.predict(image_file)\n",
    "        \n",
    "        # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "        if Prediction.argmax()   == 0:\n",
    "            Emotion = 'Angry'\n",
    "        elif Prediction.argmax() == 1:\n",
    "            Emotion = 'Disgust'\n",
    "        elif Prediction.argmax() == 2:\n",
    "            Emotion = 'Fear'\n",
    "        elif Prediction.argmax() == 3:\n",
    "            Emotion = 'Happy'            \n",
    "        elif Prediction.argmax() == 4:\n",
    "            Emotion = 'Sad'            \n",
    "        elif Prediction.argmax() == 5:\n",
    "            Emotion = 'Surprise'            \n",
    "        elif Prediction.argmax() == 6:\n",
    "            Emotion = 'Neutral'        \n",
    "            \n",
    "        return Emotion, Prediction\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "def Facial_Expression_Recognition(Test_Facial, Frontal_Face_Detection_XML, Profile_Face_Detection_XML, Eyes_Detection_XML):\n",
    "\n",
    "#######    ########  ######   #######   ######   ##      # ####### ####### #######  #######  ##      #                     \n",
    "##     ##  #        ##     # ##     ## ##        ###     #    #       #       #    ##     ## ###     #\n",
    "##     ##  #        ##       ##     ## ##        #  #    #    #       #       #    ##     ## #  #    #     \n",
    "#######    ######   ##       ##     ## ##   #### #   #   #    #       #       #    ##     ## #   #   #     \n",
    "##    ##   #        ##       ##     ## ##     ## #    #  #    #       #       #    ##     ## #    #  #           \n",
    "##     ##  #        ##     # ##     ## ##     ## #     ###    #       #       #    ##     ## #     ###            \n",
    "##      ## ########  ######   #######   #######  #      ## #######    #    #######  #######  #      ##                      \n",
    "\n",
    "\n",
    "    # Angle of face detection\n",
    "    Frontal_face_cascade = cv2.CascadeClassifier(Frontal_Face_Detection_XML)\n",
    "    Profile_face_cascade = cv2.CascadeClassifier(Profile_Face_Detection_XML)\n",
    "    eye_cascade  = cv2.CascadeClassifier(Eyes_Detection_XML)\n",
    "\n",
    "\n",
    "    VideoFrame = cv2.VideoCapture(0)\n",
    "    VideoFrame.set(4,640) # set Width\n",
    "    VideoFrame.set(5,480) # set Height    \n",
    "    while(True):\n",
    "        ret, image_file_for_display = VideoFrame.read()\n",
    "        image_file_for_display = cv2.flip(image_file_for_display, 1)\n",
    "        image_file = cv2.cvtColor(image_file_for_display, cv2.COLOR_BGR2GRAY)\n",
    "        faces = Frontal_face_cascade.detectMultiScale(image_file_for_display, scaleFactor=1.25, minNeighbors=5, \\\n",
    "                minSize=(10, 10))\n",
    "        \n",
    "        for (x,y,w,h) in faces:  \n",
    "            Emotion, Prediction = Facial_Expression_Prediction(image_file[y:y+h,x:x+w])\n",
    "            cv2.putText(image_file_for_display, str(Emotion) + \" \" + str(round(Prediction[0][Prediction.argmax()]*100,1)) + \"%\", \\\n",
    "                        org=(x,y-10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.0,                       \\\n",
    "                        color=(0, 0, 255), thickness=1                    \n",
    "                       )            \n",
    "            cv2.rectangle(image_file_for_display,(x,y),(x+w,y+h),(0,0,255),2) \n",
    "            \n",
    "        cv2.imshow('Colour', image_file_for_display)\n",
    "##        cv2.imshow('Non-Colour', image_file)\n",
    "    \n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    VideoFrame.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def Duration_Calculation():        \n",
    "\n",
    "########### ###### ###       ### #######              \n",
    "    ##        ##   ####     #### #                 \n",
    "    ##        ##   ##  #   #  ## #                  \n",
    "    ##        ##   ##   # #   ## #####                 \n",
    "    ##        ##   ##    #    ## #                   \n",
    "    ##        ##   ##         ## #    \n",
    "    ##      ###### ##         ## ########            \n",
    "                     \n",
    "    EndTime = time.time()\n",
    "    EndDateTime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "    # Calculate script Runtime\n",
    "    Duration = EndTime - StartTime\n",
    "    hours = Duration//3600\n",
    "    Duration = Duration - 3600*hours\n",
    "    minutes = Duration//60\n",
    "    seconds = Duration - 60*minutes\n",
    "    \n",
    "    print(\"Start:\", StartDateTime,                                      '\\t    Loss:', round(score[0], 3)   )\n",
    "    print(\"End  :\", EndDateTime,                                        '\\tAccuracy:', round(score[1], 3)   )\n",
    "    print('Runtime: %d Hrs %d Min %d Sec' %(hours,minutes,seconds)) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "\n",
    "        \n",
    "###     ###      ###      ## ###    ##           \n",
    "####   ####     ## ##     ## ####   ##                 \n",
    "## ## ## ##    ##   ##    ## ## ##  ##              \n",
    "##  ###  ##   #########   ## ##  ## ##                  \n",
    "##       ##  ##       ##  ## ##   ####                         \n",
    "##       ## ##         ## ## ##    ###                       \n",
    "\n",
    "# Script process Start Time\n",
    "StartTime = time.time()\n",
    "StartDateTime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "\n",
    "Current_Dir = os.getcwd()              # Get this script current directory\n",
    "\n",
    "\n",
    "                        ########## LOCATION OF INPUTS, FOLDERS & IMAGES ##########\n",
    "# Train Data Location    \n",
    "Train_Facial_Expression = os.path.join(Current_Dir,'Train_DATA\\Train_DATA_Facial_Expressions.csv')  \n",
    "\n",
    "# Test Data Location\n",
    "Test_Facial = [os.path.join(Current_Dir,'DATA',X) for X in os.listdir(os.path.join(Current_Dir,'DATA'))]   \n",
    "\n",
    "# Frontal Face Detection\n",
    "Frontal_Face_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Profile Face Detection\n",
    "Profile_Face_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_profileface.xml')\n",
    "\n",
    "# Eyes Detection\n",
    "Eyes_Detection_XML = os.path.join(Current_Dir,'Face_Detection\\haarcascade_eye.xml')\n",
    "    \n",
    "\n",
    "                        ########## FUNCTIONS ##########\n",
    "ImageArray, Emotion_No, EmotionList = Read_TrainDATA_Facial_Expression()\n",
    "score, model = Machine_Learning_Model(ImageArray)\n",
    "Facial_Expression_Recognition(Test_Facial, Frontal_Face_Detection_XML, Profile_Face_Detection_XML, Eyes_Detection_XML)\n",
    "Duration_Calculation()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
